# LangChain Python Service

Multi-agent LLM service v·ªõi **H·ªá th·ªëng l√Ω lu·∫≠n ƒëa t·∫ßng (Multi-Layered Reasoning System)** v√† t·ªëi ∆∞u h√≥a chuy√™n s√¢u.

## üöÄ Features

### Core Features

- ‚úÖ **Smart Single Context** v·ªõi token budget management
- ‚úÖ **H·ªá th·ªëng l√Ω lu·∫≠n ƒëa t·∫ßng** - ph√¢n t√≠ch ng·ªØ c·∫£nh, persona, phong c√°ch, v√† chuy√™n ng√†nh
- ‚úÖ **Token-based Compression** - t·ªëi ∆∞u h√≥a chi ph√≠ v√† performance
- ‚úÖ Single agent chat v·ªõi context optimization
- ‚úÖ Multi-agent conversations v·ªõi parallel processing
- ‚úÖ OpenRouter.ai integration (100+ models)
- ‚úÖ Async processing v·ªõi smart caching
- ‚úÖ FastAPI v·ªõi auto docs
- ‚úÖ Docker support

### üÜï Phase 6: Generator-Critique Architecture for Outlines

- ‚úÖ **Chu·ªói Agent "T·∫°o sinh - Ph·∫£n bi·ªán"**: M·ªôt Agent chuy√™n t·∫°o b·∫£n nh√°p chi ti·∫øt v√† m·ªôt Agent kh√°c chuy√™n review, s·ª≠a l·ªói v√† ho√†n thi·ªán, m√¥ ph·ªèng quy tr√¨nh l√†m vi·ªác c·ªßa chuy√™n gia.
- ‚úÖ **Ph√¢n t√≠ch Chuy√™n ng√†nh & Ph∆∞∆°ng ph√°p lu·∫≠n**: T·ª± ƒë·ªông √°p d·ª•ng c√°c ph∆∞∆°ng ph√°p h·ªçc t·∫≠p ri√™ng cho t·ª´ng lƒ©nh v·ª±c (L·∫≠p tr√¨nh, Ngo·∫°i ng·ªØ, Khoa h·ªçc...) ƒë·ªÉ t·∫°o outline c√≥ chi·ªÅu s√¢u.
- ‚úÖ **ƒê√°nh gi√° Tr√¨nh ƒë·ªô Ng∆∞·ªùi d√πng**: Ph√¢n t√≠ch y√™u c·∫ßu ƒë·ªÉ x√°c ƒë·ªãnh c·∫•p ƒë·ªô (Beginner, Intermediate, Expert) v√† ƒëi·ªÅu ch·ªânh n·ªôi dung cho ph√π h·ª£p.
- ‚úÖ **"Prompt ƒê·ªông"**: T·ª± ƒë·ªông "b∆°m" c√°c ch·ªâ d·∫´n v·ªÅ ph∆∞∆°ng ph√°p lu·∫≠n v√† tr√¨nh ƒë·ªô v√†o prompt ƒë·ªÉ c√° nh√¢n h√≥a k·∫øt qu·∫£ ·ªü m·ª©c ƒë·ªô cao.

### üÜï Phase 5: Adaptive Learning & Personalization

- ‚úÖ **Adaptive Difficulty:** AI t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh ƒë·ªô ph·ª©c t·∫°p c·ªßa c√¢u tr·∫£ l·ªùi (Beginner, Intermediate, Expert) d·ª±a tr√™n tr√¨nh ƒë·ªô ƒë√£ ƒë∆∞·ª£c theo d√µi c·ªßa ng∆∞·ªùi d√πng trong t·ª´ng ch·ªß ƒë·ªÅ.
- ‚úÖ **Knowledge Gap Analysis:** AI c√≥ kh·∫£ nƒÉng ph√°t hi·ªán c√°c "l·ªó h·ªïng ki·∫øn th·ª©c" ti·ªÅm ·∫©n (v√≠ d·ª•: ng∆∞·ªùi d√πng h·ªèi c√¢u h·ªèi n√¢ng cao v·ªÅ m·ªôt ch·ªß ƒë·ªÅ m√† h·ªç ch∆∞a n·∫Øm v·ªØng ki·∫øn th·ª©c c∆° b·∫£n) v√† ch·ªß ƒë·ªông ƒë·ªÅ xu·∫•t c√°c l·ªô tr√¨nh h·ªçc t·∫≠p hi·ªáu qu·∫£ h∆°n.
- ‚úÖ **Personalized Learning State:** H·ªá th·ªëng theo d√µi v√† l∆∞u tr·ªØ tr·∫°ng th√°i h·ªçc t·∫≠p c·ªßa ng∆∞·ªùi d√πng tr√™n t·ª´ng topic, t·∫°o ra m·ªôt tr·∫£i nghi·ªám h·ªçc t·∫≠p ƒë∆∞·ª£c c√° nh√¢n h√≥a s√¢u s·∫Øc qua c√°c session.

### üÜï Phase 4: Multi-Layered Reasoning & Communication

- ‚úÖ **Tri·∫øt l√Ω giao ti·∫øp 2 c·∫•p ƒë·ªô**: "Khung Giao ti·∫øp" (lu√¥n √°p d·ª•ng) v√† "Ph∆∞∆°ng ph√°p Chuy√™n m√¥n" (linh ho·∫°t) ƒë·∫£m b·∫£o m·ªçi c√¢u tr·∫£ l·ªùi ƒë·ªÅu chuy√™n nghi·ªáp v√† ƒë√∫ng ng·ªØ c·∫£nh.
- ‚úÖ **Intelligent Persona Engine**: T·ª± ƒë·ªông ch·ªçn ph∆∞∆°ng ph√°p chuy√™n m√¥n (Socratic, K·ªπ s∆∞, S√°ng t·∫°o, Tr·ª±c ti·∫øp) d·ª±a tr√™n nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng.
- ‚úÖ **Domain-Specific Priming**: T·ª± ƒë·ªông "b·ªìi d∆∞·ª°ng" cho AI c√°c quy t·∫Øc chuy√™n ng√†nh (L·∫≠p tr√¨nh, Khoa h·ªçc,...) ƒë·ªÉ c√¢u tr·∫£ l·ªùi c√≥ chi·ªÅu s√¢u v√† ch√≠nh x√°c h∆°n.
- ‚úÖ **Dynamic Output Control**: Ng∆∞·ªùi d√πng c√≥ th·ªÉ ƒëi·ªÅu khi·ªÉn ƒë·ªô d√†i (ng·∫Øn g·ªçn/chi ti·∫øt) v√† s·ª± m·ªõi m·∫ª c·ªßa c√¢u tr·∫£ l·ªùi.
- ‚úÖ **Relevance-Aware Responses**: AI nh·∫≠n bi·∫øt c√¢u h·ªèi l·∫°c ƒë·ªÅ v√† ƒë∆∞a ra c√°c x·ª≠ l√Ω ph√π h·ª£p, gi√∫p duy tr√¨ d√≤ng h·ªçc t·∫≠p.
- ‚úÖ **Context-Rich Model Routing**: B·ªô ƒë·ªãnh tuy·∫øn model s·ª≠ d·ª•ng c·∫£ ng·ªØ c·∫£nh bu·ªïi h·ªçc (topic/node) v√† c√¢u h·ªèi hi·ªán t·∫°i ƒë·ªÉ ch·ªçn model t·ªëi ∆∞u nh·∫•t.

### üÜï Phase 5: Adaptive Learning & Personalization

- ‚úÖ **Adaptive Difficulty:** AI t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh ƒë·ªô ph·ª©c t·∫°p c·ªßa c√¢u tr·∫£ l·ªùi (Beginner, Intermediate, Expert) d·ª±a tr√™n tr√¨nh ƒë·ªô ƒë√£ ƒë∆∞·ª£c theo d√µi c·ªßa ng∆∞·ªùi d√πng trong t·ª´ng ch·ªß ƒë·ªÅ.
- ‚úÖ **Knowledge Gap Analysis:** AI c√≥ kh·∫£ nƒÉng ph√°t hi·ªán c√°c "l·ªó h·ªïng ki·∫øn th·ª©c" ti·ªÅm ·∫©n (v√≠ d·ª•: ng∆∞·ªùi d√πng h·ªèi c√¢u h·ªèi n√¢ng cao v·ªÅ m·ªôt ch·ªß ƒë·ªÅ m√† h·ªç ch∆∞a n·∫Øm v·ªØng ki·∫øn th·ª©c c∆° b·∫£n) v√† ch·ªß ƒë·ªông ƒë·ªÅ xu·∫•t c√°c l·ªô tr√¨nh h·ªçc t·∫≠p hi·ªáu qu·∫£ h∆°n.
- ‚úÖ **Personalized Learning State:** H·ªá th·ªëng theo d√µi v√† l∆∞u tr·ªØ tr·∫°ng th√°i h·ªçc t·∫≠p c·ªßa ng∆∞·ªùi d√πng tr√™n t·ª´ng topic, t·∫°o ra m·ªôt tr·∫£i nghi·ªám h·ªçc t·∫≠p ƒë∆∞·ª£c c√° nh√¢n h√≥a s√¢u s·∫Øc qua c√°c session.

### üÜï Phase 3: Advanced Optimization Features

- ‚úÖ **Context Quality Analysis** - Real-time quality scoring (relevance, completeness, efficiency, coherence, freshness)
- ‚úÖ **Performance Monitoring** - System metrics tracking v·ªõi alert system
- ‚úÖ **Optimization Reports** - Comprehensive recommendations for cost & performance improvements
- ‚úÖ **Real-time Alerts** - Critical performance issue notifications
- ‚úÖ **Monitoring Dashboard** - Complete system health overview
- ‚úÖ **Stress Testing** - Load testing v·ªõi automatic alert triggering

### üÜï Phase 2: Intelligent Routing & Dynamic Personas

- ‚úÖ **Intelligent Model Routing**: T·ª± ƒë·ªông ch·ªçn model t·ªëi ∆∞u (chi ph√≠/hi·ªáu nƒÉng) d·ª±a tr√™n lƒ©nh v·ª±c chuy√™n m√¥n (L·∫≠p tr√¨nh, Khoa h·ªçc,...) v√† ƒë·ªô ph·ª©c t·∫°p c·ªßa c√¢u h·ªèi.
- ‚úÖ **Dynamic Persona Engine**: Agent c√≥ th·ªÉ thay ƒë·ªïi "t√≠nh c√°ch" (Mentor, S√°ng t·∫°o, K·ªπ s∆∞) ƒë·ªÉ ph√π h·ª£p v·ªõi ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán.
- ‚úÖ **Structural Context Awareness**: Agent "hi·ªÉu" ƒë∆∞·ª£c b·ªëi c·∫£nh b√†i h·ªçc (ch·ªß ƒë·ªÅ, m·ª•c ƒëang h·ªçc) ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi li√™n quan h∆°n.

#### Intelligent Routing Flow

```mermaid
graph TD
    subgraph "1. Input Layer"
        A[User Message + Session Info]
    end

    subgraph "2. Context & Routing Layer"
        A --> B{Lightweight Router};
        B -- Standalone? --> C[Skip Context];
        B -- Needs Context --> D[DB Context Manager];
        D --> E[ContextPackage];
        E --> F[Persona Engine];
        E --> G[Model Router];
        F -- Persona --> H[Prompt Builder];
        G -- Selected Model --> H;
        E -- Context Info --> H;
    end

    subgraph "3. Execution Layer"
        H --> I[Orchestrator];
        I --> J[LLM API];
        J --> K[Streaming Response];
    end
```

## üß† Tri·∫øt l√Ω h·ªá th·ªëng: L√Ω lu·∫≠n ƒëa t·∫ßng & Ph·∫£n bi·ªán

H·ªá th·ªëng kh√¥ng c√≤n ho·∫°t ƒë·ªông nh∆∞ m·ªôt chatbot h·ªèi-ƒë√°p ƒë∆°n thu·∫ßn. Thay v√†o ƒë√≥, m·ªói y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng s·∫Ω ƒëi qua m·ªôt **h·ªá th·ªëng l√Ω lu·∫≠n ƒëa t·∫ßng** ƒë·ªÉ ƒë·∫£m b·∫£o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng l√† th√¥ng minh, ph√π h·ª£p v√† h·ªØu √≠ch nh·∫•t.

### 1. Lu·ªìng x·ª≠ l√Ω Chat th√¥ng minh (Intelligent Routing Flow)

Ki·∫øn tr√∫c n√†y ƒë∆∞·ª£c √°p d·ª•ng cho c√°c t√°c v·ª• chat t∆∞∆°ng t√°c, t·ªëi ∆∞u h√≥a vi·ªác l·ª±a ch·ªçn model, persona v√† ng·ªØ c·∫£nh ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi.

```mermaid
graph TD
    subgraph "1. Input Layer"
        A[User Message + Session Info]
    end

    subgraph "2. Context & Routing Layer"
        A --> B{Lightweight Router};
        B -- Standalone? --> C[Skip Context];
        B -- Needs Context --> D[DB Context Manager];
        D --> E[ContextPackage];
        E --> F[Persona Engine];
        E --> G[Model Router];
        F -- Persona --> H[Prompt Builder];
        G -- Selected Model --> H;
        E -- Context Info --> H;
    end

    subgraph "Intelligence Layer (in main.py)"
        C & A --> D{Multi-Layered Analysis<br/>- Proficiency<br/>- Relevance<br/>- Persona<br/>- Style<br/>- Domain};
        D --> E[Instruction Set<br/>(All guidances & persona)];
        D --> F[Selected Model];
    end
```

### 2. Ki·∫øn tr√∫c "T·∫°o sinh - Ph·∫£n bi·ªán" cho vi·ªác t·∫°o L·ªô tr√¨nh h·ªçc

ƒê·ªÉ t·∫°o ra c√°c l·ªô tr√¨nh h·ªçc ch·∫•t l∆∞·ª£ng cao, h·ªá th·ªëng √°p d·ª•ng m·ªôt ki·∫øn tr√∫c "Generator-Critique" m·∫°nh m·∫Ω, ƒë√¢y l√† m·ªôt v√≠ d·ª• ƒëi·ªÉn h√¨nh c·ªßa tri·∫øt l√Ω l√Ω lu·∫≠n ƒëa t·∫ßng.

```mermaid
graph TD
    A[User Request] --> B{Agent A: Interpreter<br/>(Topic, Requirement, Proficiency)};

    subgraph "Parallel Execution"
        B -- Analysis --> C[Agent B: Drafter<br/>T·∫°o b·∫£n nh√°p outline ho√†n ch·ªânh];
        C -- Draft Outline --> D{Agent C: QA & Refiner<br/>Review, s·ª≠a l·ªói, v√† ho√†n thi·ªán};

        B -- Analysis --> E{Agent D: Metadata Gen<br/>(topicName, description)};
    end

    subgraph "Final Assembly"
        D -- Final Outline Text --> F[Python Parser<br/>_parse_outline_to_tree];
        F & E --> G[Combine tree + metadata];
        G --> H[Final JSON Response];
    end
```

#### T·∫°i sao Ki·∫øn tr√∫c n√†y v∆∞·ª£t tr·ªôi?

1.  **Chuy√™n m√¥n h√≥a (Specialization):** M·ªói agent ch·ªâ t·∫≠p trung v√†o m·ªôt nhi·ªám v·ª• m√† n√≥ l√†m t·ªët nh·∫•t. Agent B (Drafter) gi·ªèi v·ªÅ vi·ªác "brainstorm" m·ªôt c√°ch to√†n di·ªán. Agent C (Refiner) gi·ªèi v·ªÅ vi·ªác "bi√™n t·∫≠p" v√† t√¨m l·ªói.
2.  **Ch·∫•t l∆∞·ª£ng ƒë·∫£m b·∫£o (Quality Assurance):** B∆∞·ªõc ph·∫£n bi·ªán c·ªßa Agent C ho·∫°t ƒë·ªông nh∆∞ m·ªôt l·ªõp QA t·ª± ƒë·ªông, gi√∫p ph√°t hi·ªán nh·ªØng thi·∫øu s√≥t, s·ª± l·∫∑p l·∫°i ho·∫∑c c√°c ƒëi·ªÉm ch∆∞a logic m√† m·ªôt agent duy nh·∫•t c√≥ th·ªÉ b·ªè qua.
3.  **Hi·ªáu nƒÉng (Performance):** C√°c t√°c v·ª• ƒë·ªôc l·∫≠p (t·∫°o outline v√† t·∫°o metadata) v·∫´n ƒë∆∞·ª£c th·ª±c thi song song, gi√∫p t·ªëi ∆∞u th·ªùi gian ph·∫£n h·ªìi.
4.  **Minh b·∫°ch & D·ªÖ g·ª° l·ªói:** Vi·ªác t√°ch c√°c b∆∞·ªõc gi√∫p ch√∫ng ta d·ªÖ d√†ng xem x√©t output c·ªßa t·ª´ng agent v√† x√°c ƒë·ªãnh ch√≠nh x√°c v·∫•n ƒë·ªÅ n·∫±m ·ªü ƒë√¢u trong chu·ªói.

## üß† Adaptive Learning Engine

H·ªá th·ªëng gi·ªù ƒë√¢y kh√¥ng ch·ªâ tr·∫£ l·ªùi c√¢u h·ªèi, m√† c√≤n ch·ªß ƒë·ªông t√¨m c√°ch hi·ªÉu tr√¨nh ƒë·ªô c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ t·∫°o ra m·ªôt l·ªô tr√¨nh h·ªçc t·∫≠p ƒë∆∞·ª£c c√° nh√¢n h√≥a.

### How It Works

1.  **Knowledge State Tracking:** H·ªá th·ªëng duy tr√¨ m·ªôt `user_knowledge_state` (d·∫°ng JSONB trong DB) cho m·ªói session, theo d√µi tr√¨nh ƒë·ªô c·ªßa ng∆∞·ªùi d√πng (`Beginner`, `Intermediate`, `Expert`) tr√™n t·ª´ng m·ª•c h·ªçc (node).
2.  **Proficiency Analysis:** V·ªõi m·ªói tin nh·∫Øn m·ªõi, m·ªôt b·ªô ph√¢n t√≠ch trong `main.py` s·∫Ω ƒë√°nh gi√° ng√¥n ng·ªØ c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ ph√°t hi·ªán c√°c t√≠n hi·ªáu v·ªÅ s·ª± hi·ªÉu bi·∫øt c·ªßa h·ªç (v√≠ d·ª•: h·ªèi "l√† g√¨" so v·ªõi "∆∞u nh∆∞·ª£c ƒëi·ªÉm v·ªÅ hi·ªáu nƒÉng").
3.  **Adaptive Instruction:** D·ª±a tr√™n tr√¨nh ƒë·ªô ƒë√£ ƒë∆∞·ª£c theo d√µi, m·ªôt ch·ªâ d·∫´n `adaptive_difficulty_guidance` s·∫Ω ƒë∆∞·ª£c ƒë∆∞a v√†o prompt ƒë·ªÉ ra l·ªánh cho AI:
    - **V·ªõi ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu:** D√πng ng√¥n ng·ªØ ƒë∆°n gi·∫£n, nhi·ªÅu so s√°nh, t·∫≠p trung v√†o "C√°i g√¨" v√† "T·∫°i sao".
    - **V·ªõi ng∆∞·ªùi c√≥ kinh nghi·ªám:** T·∫≠p trung v√†o ·ª©ng d·ª•ng, so s√°nh v√† c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng th·ª±c t·∫ø.
    - **V·ªõi chuy√™n gia:** T·∫≠p trung v√†o c√°c ch·ªß ƒë·ªÅ n√¢ng cao, t·ªëi ∆∞u h√≥a, v√† ph√¢n t√≠ch ki·∫øn tr√∫c.

## User-Driven Controls

Gi·ªù ƒë√¢y, ng∆∞·ªùi d√πng c√≥ th·ªÉ ch·ªß ƒë·ªông ƒë·ªãnh h√¨nh cu·ªôc tr√≤ chuy·ªán b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c c·ª•m t·ª´ t·ª± nhi√™n:

- **C·∫ßn c√¢u tr·∫£ l·ªùi th·∫≥ng:** _"t√¥i kh√¥ng bi·∫øt"_, _"gi·∫£i th√≠ch th·∫≥ng cho t√¥i"_.
- **C·∫ßn ph√¢n t√≠ch s√¢u:** _"d√πng model m·∫°nh nh·∫•t"_, _"ph√¢n t√≠ch k·ªπ"_.
- **C·∫ßn c√¢u tr·∫£ l·ªùi s√°ng t·∫°o:** _"gi·∫£i th√≠ch nh∆∞ th·ªÉ l√†..."_, _"v√≠ d·ª• vui"_.
- **C·∫ßn c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn:** _"t√≥m t·∫Øt"_, _"√Ω ch√≠nh"_.
- **C·∫ßn gi·∫£i th√≠ch l·∫°i:** _"n√≥i c√°ch kh√°c"_, _"theo m·ªôt g√≥c nh√¨n kh√°c"_.

## Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Environment Setup

```bash
cp env.example .env
# Edit .env v·ªõi your API keys
```

Required environment variables:

```env
DATABASE_URL=postgresql://user:pass@localhost:5432/dbname
OPENROUTER_API_KEY=your_openrouter_key
DEFAULT_MODEL=google/gemini-2.0-flash-lite-001
```

### 3. Database Migration (Phase 1 Cleanup)

```bash
# Run migration ƒë·ªÉ remove dual context v√† optimize storage
psql $DATABASE_URL -f deep-knowledge-ai-platform/docs/migrations/003_remove_dual_context.sql
```

### 4. Run Server

```bash
# Development
python -m app.main

# Production
uvicorn app.main:app --host 0.0.0.0 --port 5000
```

### 5. Test Smart Context API

```bash
# Health check
curl http://localhost:5000/health

# Smart chat v·ªõi context optimization
curl -X POST http://localhost:5000/smart-chat \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user123",
    "message": "Gi·∫£i th√≠ch v·ªÅ machine learning",
    "topic_id": "ai-basics",
    "model": "google/gemini-2.0-flash-lite-001"
  }'

# Response includes context optimization info:
{
  "response": "Machine learning l√†...",
  "context_info": {
    "context_type": "RECENT_ONLY",
    "estimated_tokens": 245,
    "recent_messages_count": 3
  }
}
```

## üìä Performance Benefits

### Before (Dual Context):

- Storage: 2x overhead (full + compressed)
- Query complexity: High (dual column logic)
- Token waste: ~40% over-allocation
- Processing: Multiple compression strategies

### After (Smart Single Context):

- Storage: **50% reduction**
- Performance: **2-3x faster** queries
- Token efficiency: **40-60% savings**
- Processing: **On-demand optimization**

## üîß Configuration

### Smart Context Settings

```python
# In DatabaseContextManager
max_context_tokens = 1500      # Token budget limit
recent_messages_limit = 10     # Recent context size
compression_threshold = 4500   # Auto-compress trigger
```

### Router Agent Settings

```python
# Enable LLM analysis for edge cases
enable_llm_analysis = False    # Default: rule-based only
confidence_threshold = 0.8     # LLM analysis trigger
```

## API Endpoints

### Core Chat APIs

#### `/smart-chat` - Intelligent Context Chat

T·ª± ƒë·ªông optimize context d·ª±a tr√™n router analysis:

- Ph√¢n t√≠ch message ƒë·ªÉ quy·∫øt ƒë·ªãnh context type
- Apply token budget management
- Progressive context loading
- Smart compression khi c·∫ßn
- **NEW**: Real-time quality metrics trong response

#### `/chat` - Standard Single Agent

Basic chat without context optimization (legacy support)

#### `/multi-agent` - Multi-Agent Conversations

Parallel agent processing cho complex discussions

### üÜï Monitoring & Optimization APIs

#### `/monitoring/performance` - Performance Metrics

```bash
GET /monitoring/performance?hours_back=24
```

Comprehensive performance metrics: response times, quality scores, efficiency trends

#### `/monitoring/quality` - Quality Trends

```bash
GET /monitoring/quality?hours_back=24
```

Context quality analysis trends v√† token usage optimization insights

#### `/monitoring/alerts` - Real-time Alerts

```bash
GET /monitoring/alerts?hours_back=1
```

Performance alerts v·ªõi recommendations (critical response times, quality issues, resource usage)

#### `/monitoring/optimization-report` - Optimization Report

```bash
GET /monitoring/optimization-report
```

Comprehensive optimization analysis v·ªõi estimated improvements:

- Token usage optimization (potential 20-40% cost savings)
- Performance optimization (15-30% response time improvements)
- Quality optimization (10-25% quality score improvements)

#### `/monitoring/dashboard` - Complete Dashboard

```bash
GET /monitoring/dashboard
```

Real-time system health overview v·ªõi current metrics, alerts, v√† 24h trends

## Integration v·ªõi Node.js Backend

```typescript
// Backend-main service integration
const response = await fetch("http://localhost:5000/smart-chat", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    user_id,
    session_id, // Optional - auto-created if not provided
    message,
    topic_id, // For context isolation
    node_id, // For fine-grained context
    model: "google/gemini-2.0-flash-lite-001",
  }),
});

// Response v·ªõi context insights
const { response, context_info, session_stats } = await response.json();
```

## Development

```bash
# Install dev dependencies
pip install -r requirements.txt

# Run v·ªõi auto-reload
python -m app.main

# Test smart context v·ªõi quality analysis
python -c "
import asyncio
from app.agents.db_context_manager import DatabaseContextManager

async def test():
    manager = DatabaseContextManager()
    await manager.init_db()

    context_package, quality_metrics = await manager.get_context_for_message(
        session_id='test-123',
        user_id='user-456',
        message='Ti·∫øp t·ª•c nh∆∞ l√∫c n√£y'
    )
    print(f'Context type: {context_package.context_type}')
    print(f'Tokens: {context_package.total_tokens_estimate}')
    print(f'Quality: {quality_metrics.overall_quality:.2f} ({quality_metrics.quality_level.value})')

asyncio.run(test())
"
```

### üÜï Phase 3 Testing

```bash
# Test all advanced optimization features
python test_phase3_advanced_optimization.py

# Test specific monitoring endpoints
curl http://localhost:5000/monitoring/dashboard
curl http://localhost:5000/monitoring/optimization-report
curl http://localhost:5000/monitoring/alerts

# Performance stress testing
python -c "
import asyncio
import aiohttp

async def stress_test():
    async with aiohttp.ClientSession() as session:
        tasks = []
        for i in range(10):
            task = session.post('http://localhost:5000/smart-chat', json={
                'user_id': f'stress-{i}',
                'message': f'Complex question #{i} about AI and machine learning',
                'model': 'google/gemini-2.0-flash-lite-001'
            })
            tasks.append(task)

        responses = await asyncio.gather(*tasks, return_exceptions=True)
        successful = sum(1 for r in responses if not isinstance(r, Exception))
        print(f'Stress test: {successful}/10 successful requests')

asyncio.run(stress_test())
"
```

## Smart Context Strategies

### 1. NONE Context (0 tokens)

- Standalone questions: "Xin ch√†o", "AI l√† g√¨?"
- Topic switches: "Chuy·ªÉn ch·ªß ƒë·ªÅ m·ªõi"

### 2. RECENT_ONLY (~300 tokens)

- Continuation: "Ti·∫øp t·ª•c", "Nh∆∞ b·∫°n v·ª´a n√≥i"
- Clarification: "√ù b·∫°n l√† g√¨?"

### 3. SMART_RETRIEVAL (~800 tokens)

- Historical reference: "V·ªÅ v·∫•n ƒë·ªÅ X tu·∫ßn tr∆∞·ªõc"
- Topic search: "Li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ Y"

### 4. FULL_CONTEXT (~1500 tokens)

- Summary requests: "T√≥m t·∫Øt cu·ªôc h·ªôi tho·∫°i"
- Complete review: "Review l·∫°i to√†n b·ªô"

## Migration Guide

### From Dual Context to Smart Single Context:

1. **Backup Database** (recommended)
2. **Run migration**: `003_remove_dual_context.sql`
3. **Update Python code** (already completed)
4. **Test smart context** v·ªõi existing sessions
5. **Monitor performance** improvements

Expected results:

- 50% storage reduction
- 2-3x faster context queries
- 40-60% token cost savings
- Better user experience v·ªõi smart context decisions

## üìä Phase 3 Advanced Optimization Results

### Quality Analysis Benefits

- **Real-time Quality Scoring**: 5 dimensions (relevance, completeness, efficiency, coherence, freshness)
- **Quality Trends**: Track improvement patterns over time
- **Automatic Optimization**: Low-quality contexts trigger automatic improvements

### Performance Monitoring Benefits

- **Proactive Alerts**: Critical issues detected before user impact
- **Resource Optimization**: CPU/Memory usage tracking v·ªõi smart thresholds
- **Response Time Monitoring**: P95/P99 percentile tracking for SLA compliance

### Optimization Reports Benefits

- **Cost Savings**: 20-40% potential token cost reduction
- **Performance Gains**: 15-30% response time improvements
- **Quality Improvements**: 10-25% context quality score enhancements
- **Actionable Insights**: Specific recommendations v·ªõi estimated impact

### Production-Ready Features

- **Enterprise Monitoring**: Complete observability stack
- **Alert Management**: Critical issue notifications v·ªõi recommendations
- **Optimization Automation**: Self-improving system performance
- **Performance SLAs**: Quantified quality v√† performance metrics
