# ğŸ› Debug Guide - Smart AI Conversation System

## Kiáº¿n trÃºc má»›i (Simplified v3.0.0)

Sau khi refactor, há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hÃ³a tá»« **1,900+ lines** xuá»‘ng cÃ²n **~600 lines** vá»›i 4 components chÃ­nh:

### âœ… **Components má»›i (Clean & Smart)**

1. **SmartContextManager** (230 lines)

   - Thay tháº¿: DatabaseContextManager phá»©c táº¡p
   - Chá»©c nÄƒng: Context management thÃ´ng minh
   - Debug symbols: `ğŸ” [CONTEXT]`

2. **ConversationIntelligence** (200 lines)

   - Thay tháº¿: Logic persona phÃ¢n tÃ¡n
   - Chá»©c nÄƒng: Dynamic persona selection
   - Debug symbols: `ğŸ§  [INTELLIGENCE]`

3. **SimplifiedOrchestrator** (150 lines)

   - Thay tháº¿: Multi-agent complexity
   - Chá»©c nÄƒng: Clean conversation flow
   - Debug symbols: `ğŸ­ [ORCHESTRATOR]`

4. **Smart Main.py** (Updated)
   - Thay tháº¿: Over-engineered endpoints
   - Chá»©c nÄƒng: Streamlined API
   - Debug symbols: `ğŸš€ [SMART-CHAT]`

### âŒ **Components Ä‘Ã£ xÃ³a (Over-engineered)**

- âœ— ContextQualityAnalyzer (566 lines)
- âœ— PerformanceMonitor (757 lines)
- âœ— ContentCompressor (587 lines)
- âœ— DatabaseContextManager (deprecated)

---

## ğŸš€ **CÃ¡ch enable Debug Mode**

### **Option 1: Quick Enable**

```bash
cd langchain-python-service
python debug_config.py
```

### **Option 2: Manual Environment**

```bash
export DEBUG_AGENTS=true
export DEBUG_CONTEXT=true
export DEBUG_INTELLIGENCE=true
export DEBUG_ORCHESTRATOR=true
export DEBUG_MAIN=true
export LOG_LEVEL=DEBUG
```

### **Option 3: Docker Debug**

```dockerfile
ENV DEBUG_AGENTS=true
ENV DEBUG_CONTEXT=true
ENV DEBUG_INTELLIGENCE=true
ENV DEBUG_ORCHESTRATOR=true
ENV DEBUG_MAIN=true
```

---

## ğŸ“Š **Debug Symbols & Flow Tracking**

### **Main Conversation Flow**

```
ğŸš€ [SMART-CHAT] Request start
ğŸš€ [SMART-CHAT] Step 1: Creating session...
ğŸš€ [SMART-CHAT] Step 2: Saving user message...
ğŸš€ [SMART-CHAT] Step 3: Building context...
ğŸ” [CONTEXT] Building context for session...
ğŸ” [CONTEXT] Found X recent messages
ğŸ” [CONTEXT] Relevance score: X.XXX
âœ… [CONTEXT] Built in X.XXXs - XXX tokens

ğŸš€ [SMART-CHAT] Step 4: Selecting model...
ğŸš€ [SMART-CHAT] Step 5: Analyzing conversation...
ğŸ§  [INTELLIGENCE] Analyzing message...
ğŸ§  [INTELLIGENCE] Detected learning style: explorer
ğŸ§  [INTELLIGENCE] Selected persona: Socratic Mentor
âœ… [INTELLIGENCE] Analysis complete

ğŸš€ [SMART-CHAT] Step 6: Building system prompt...
ğŸš€ [SMART-CHAT] Step 7: Sending metadata...
ğŸš€ [SMART-CHAT] Step 8: Starting AI response stream...
ğŸ­ [ORCHESTRATOR] Starting response generation
ğŸ­ [ORCHESTRATOR] Persona: Socratic Mentor
ğŸ­ [ORCHESTRATOR] Starting stream...
âœ… [ORCHESTRATOR] Conversation completed in X.XXs

âœ… [SMART-CHAT] Completed in X.XXs - XXX chars
```

### **Error Tracking**

```
âŒ [SMART-CHAT] Error: Connection timeout
âŒ [CONTEXT] Error details: TimeoutError: Database timeout
âŒ [ORCHESTRATOR] Chat stream error: Model unavailable
```

### **Performance Monitoring**

```
âš¡ [CONTEXT] Optimizing - tokens exceed limit (3500 > 3000)
âš¡ [CONTEXT] Optimized: 15 -> 10 messages
```

---

## ğŸ“‚ **Log Files Location**

### **Debug Logs**

```
langchain-python-service/
â””â”€â”€ debug-logs/
    â”œâ”€â”€ smart_chat_debug.log    # All debug information
    â”œâ”€â”€ errors.log              # Errors only
    â””â”€â”€ archived/               # Rotated logs
```

### **Log Format**

```
2024-01-20 10:30:45.123 | DEBUG    | app.agents.smart_context_manager:get_smart_context:105 | ğŸ” [CONTEXT] Building context for session: 12345678...
```

---

## ğŸ¯ **Key Tracking Points**

### **1. Context Building Process**

- Session creation/retrieval
- Message history loading
- Topic context extraction
- Token estimation & optimization
- Relevance scoring

### **2. Persona Selection Logic**

- User learning style detection
- Message intent analysis
- Persona confidence scoring
- Output style determination

### **3. Model Routing Decisions**

- Domain detection
- Model selection criteria
- Temperature & token limits
- Fallback strategies

### **4. Response Generation**

- System prompt construction
- Message history formatting
- Streaming chunk processing
- Response saving

### **5. Performance Metrics**

- Context building time
- Model response time
- Total request duration
- Token usage tracking

---

## ğŸ”§ **Common Debug Scenarios**

### **Persona khÃ´ng Ä‘Ãºng**

```bash
# Track persona selection
grep "ğŸ§  \[INTELLIGENCE\]" debug-logs/smart_chat_debug.log | tail -20
```

### **Context bá»‹ thiáº¿u**

```bash
# Track context building
grep "ğŸ” \[CONTEXT\]" debug-logs/smart_chat_debug.log | tail -20
```

### **Model selection issues**

```bash
# Track model routing
grep "ğŸš€ \[SMART-CHAT\] Step 4" debug-logs/smart_chat_debug.log
```

### **Streaming problems**

```bash
# Track orchestrator
grep "ğŸ­ \[ORCHESTRATOR\]" debug-logs/smart_chat_debug.log | tail -20
```

### **Performance issues**

```bash
# Track timing
grep "Completed in" debug-logs/smart_chat_debug.log | tail -10
```

---

## ğŸ“ˆ **Performance Monitoring**

### **Thresholds**

- Context building: < 0.5s
- Model routing: < 0.1s
- Persona selection: < 0.1s
- Total request: < 3.0s

### **Alerts**

- Slow query threshold: 1.0s
- Context token limit: 3000
- Session timeout: 30s

---

## ğŸ§ª **Testing Debug System**

### **Test Request**

```bash
curl -X POST http://localhost:5000/smart-chat \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "test_user",
    "message": "Giáº£i thÃ­ch vá» machine learning",
    "topic_id": "ml_basics"
  }'
```

### **Expected Debug Output**

```
ğŸš€ [SMART-CHAT] New request from user: test_use...
ğŸ” [CONTEXT] Building context for session: abcd1234...
ğŸ§  [INTELLIGENCE] Selected persona: Creative Explorer
ğŸ­ [ORCHESTRATOR] Starting conversation with gemini-2.0-flash-lite-001
âœ… [SMART-CHAT] Completed in 2.34s - 1234 chars
```

---

## ğŸ­ **CÃ¡ch há»‡ thá»‘ng hoáº¡t Ä‘á»™ng (Overview)**

### **1. Smart Context Management**

- Tá»± Ä‘á»™ng detect standalone messages (chÃ o há»i, etc.)
- Intelligent context building vá»›i relevance scoring
- Token optimization khi vÆ°á»£t limit
- Session isolation theo topic/node

### **2. Dynamic Persona Selection**

- PhÃ¢n tÃ­ch learning style cá»§a user
- Chá»n persona phÃ¹ há»£p (Socratic/Creative/Pragmatic/Direct)
- Confidence scoring vÃ  reasoning
- Topic relevance guidance

### **3. Intelligent Model Routing**

- Domain detection (Programming/Business/Education/etc.)
- Model selection based on complexity
- Temperature adjustment per domain
- Fallback strategies

### **4. Streamlined Response Generation**

- Single model approach (khÃ´ng multi-agent)
- Smart system prompt building
- Efficient streaming
- Error recovery

### **Benefits cá»§a Architecture má»›i:**

- âœ… 90% Ã­t code phá»©c táº¡p hÆ¡n
- âœ… Response time nhanh hÆ¡n
- âœ… Easier maintenance & debugging
- âœ… Fewer points of failure
- âœ… Clear separation of concerns

---

## ğŸš¨ **Troubleshooting**

### **Debug khÃ´ng hoáº¡t Ä‘á»™ng**

```bash
# Check environment variables
python -c "import os; print({k:v for k,v in os.environ.items() if 'DEBUG' in k})"

# Check log files
ls -la debug-logs/
tail -f debug-logs/smart_chat_debug.log
```

### **Performance issues**

```bash
# Check slow operations
grep "exceed limit\|slow\|timeout" debug-logs/smart_chat_debug.log
```

### **Model errors**

```bash
# Check model routing
grep "âŒ.*model\|âŒ.*LLM" debug-logs/errors.log
```

**Happy debugging! ğŸš€**
